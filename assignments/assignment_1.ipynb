{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PHSX-bond/218-PHSX-_25/blob/main/assignments/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INkAgt-hTY_-"
      },
      "source": [
        "# Assignment 1 -  Basic Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTEAadCkTZAA"
      },
      "source": [
        "## *Cameron Bond*\n",
        "Netid: cb173374\n",
        "\n",
        "\n",
        "Note: this assignment falls under collaboration Mode 2: Individual Assignment – Collaboration Permitted. Please refer to the syllabus on Canvas for additional information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkmvTNfTZAA"
      },
      "source": [
        "Instructions for all assignments can be found [here](https://github.com/kylebradbury/ids705/blob/master/assignments/_Assignment%20Instructions.ipynb), and is also linked to from the [course syllabus](https://kylebradbury.github.io/ids705/index.html).\n",
        "\n",
        "Total points in the assignment add up to 90; an additional 10 points are allocated to presentation quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAPvzGDXTZAA"
      },
      "source": [
        "#  Learning Objectives\n",
        "The purpose of this assignment is to provide practice in fundamental concepts that we will use throughout this course. By completing this assignment, you will...\n",
        "- Practice numerical programming by loading and filtering data.\n",
        "- Learn to visuzalize and perform basic statistics on the data.\n",
        "- Apply your skills altogether through an exploratory data analysis to practice data cleaning, data manipulation, interpretation, and communication\n",
        "\n",
        "We will build on these concepts throughout the course, so use this assignment as a catalyst to deepen your knowledge and seek help with anything that is unfamiliar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZoXcmBTZAB"
      },
      "source": [
        "*Note: for all assignments, write out all equations and math using markdown and [LaTeX](https://tobi.oetiker.ch/lshort/lshort.pdf). For this assignment show ALL math work*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kS629PqTZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJo_2az4TZAD"
      },
      "source": [
        "# I/O and Numerical Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeMy78fGTZAD"
      },
      "source": [
        "## 1\n",
        "**[40 points]** Loading data and gathering insights from a real dataset\n",
        "\n",
        "In data science, we often need to find relevant resources and learn how to ask the appropriate questions (let's be honest....using Google) to find those resources. In this assignment you will be challenged to learn to use another Python data analysis library called `Pandas`.  This library is useful for organizing data into rows and columns making it easy to clean, analyze, and manipulate data. You've been introduced to it in class, but that challenge here it to use what you've learned so far and apply it to another new library.  Ready?? Here we go!   \n",
        "\n",
        "\n",
        "**Data**. The data for this problem can be found in two places. One is a simple install. The data can also be found in the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci591_CCN). The filename is `penguins.csv`. You'll use both to practice `pip install` and loading a csv file!\n",
        "\n",
        "\n",
        "This dataset consists of 7 columns.\n",
        "\n",
        "- species: penguin species (Chinstrap, Adélie, or Gentoo)\n",
        "- bill_length_mm: bill length (mm)\n",
        "- bill_depth_mm: bill depth (mm)\n",
        "- flipper_length_mm: flipper length (mm)\n",
        "- body_mass_g: body mass (g)\n",
        "- island: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica)\n",
        "- sex: penguin sex\n",
        "\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, your goal is to follow these instructions and answer the following questions:\n",
        "\n",
        "_The following questions are work 2 points each._\n",
        "\n",
        "**(a)** Load the penguins dataset using `!pip install palmerpenguins`.  Load the library using `from palmerpenguins import load_penguins` and then load the data using `penguins = load_penguins()`.  \n",
        "\n",
        "\n",
        "**(b)** Now you have the data in a `pandas.DataFrame`! Confirm that using a function we've discussed in class.\n",
        "\n",
        "**(c)** Use a new method (look it up) to return the first 10 rows of the dataset.  \n",
        "\n",
        "**(d)** Ok, now let's try to load the data another way.  This time, try to load the data from the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci191_ProgSci/tree/main/data). The filename is `penguins.csv`.  This can be tricky!  Particularly since we're working with Colab at the moment... look up how to upload the data to Colab (there are LOTS of ways to do this!) Once you do that, import the data using `pandas.read_csv()` methods and store the data in a new variable called `penguins_uploaded`. _If this is too difficult, just use the `penguins` data from part **a** for part the remaining questions._  \n",
        "\n",
        "**(e)**  `penguins_uploaded` is the same data as `penguins` in part **a** (no trickery, I promise!) but let's check ... use the `.equals()` method to confirm that.  \n",
        "\n",
        "**(f)** Assess the missing values in the data. Return a count of the NA values by column.\n",
        "\n",
        "**(g)** Ok now return a count of the number samples for each species.  \n",
        "\n",
        "**(h)** After that, use the `.dropna()` to remove any rows with missing values and store the new cleaned dataframe as `penguins_cleaned`. Again, return a count of the number samples for each species for `penguins_cleaned`. What's the difference?\n",
        "\n",
        "**(i)** Let's do some basic stats.  Use the `.describe()` method to return some descriptive statistics on the data. If you use this method on the full dataframe, do you notice any columns that are missing?  Why do you think that is?\n",
        "\n",
        "**(j)** Convert the `body_mass_g` values from grams to kg.  \n",
        "\n",
        "**(bonus +1 point)** Convert the categorical `sex` variable to numerical and rerun the `.describe()` method.  What do you notice about the output?   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFX1SSqATZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a)"
      ],
      "metadata": {
        "id": "MtoHO-MT_DOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "GDfTvpC2_5Lv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install palmerpenguins\n",
        "from palmerpenguins import load_penguins\n",
        "penguins = load_penguins()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41eDm1e9_GCS",
        "outputId": "0b2d9692-0c3e-4c82-834d-313e5b157d23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: palmerpenguins in /usr/local/lib/python3.12/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from palmerpenguins) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from palmerpenguins) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->palmerpenguins) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->palmerpenguins) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->palmerpenguins) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->palmerpenguins) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b)"
      ],
      "metadata": {
        "id": "wcJfWCXZ_ayY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(pd.DataFrame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnZs6aR_c5K",
        "outputId": "cebc12a3-3300-41e9-83e9-e69b102ce143"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c)"
      ],
      "metadata": {
        "id": "4XVu116-AG1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(penguins.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O397jsIEAxQD",
        "outputId": "eb1c7ba7-761c-4405-a7f5-a41b19fe8546"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
            "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
            "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
            "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
            "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
            "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
            "6  Adelie  Torgersen            38.9           17.8              181.0   \n",
            "7  Adelie  Torgersen            39.2           19.6              195.0   \n",
            "8  Adelie  Torgersen            34.1           18.1              193.0   \n",
            "9  Adelie  Torgersen            42.0           20.2              190.0   \n",
            "\n",
            "   body_mass_g     sex  year  \n",
            "0       3750.0    male  2007  \n",
            "1       3800.0  female  2007  \n",
            "2       3250.0  female  2007  \n",
            "3          NaN     NaN  2007  \n",
            "4       3450.0  female  2007  \n",
            "5       3650.0    male  2007  \n",
            "6       3625.0  female  2007  \n",
            "7       4675.0    male  2007  \n",
            "8       3475.0     NaN  2007  \n",
            "9       4250.0     NaN  2007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame.head(penguins, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s0Jrt0KAIc4",
        "outputId": "30afd76a-aee7-454c-a9dd-3d431a067973"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
            "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
            "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
            "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
            "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
            "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
            "6  Adelie  Torgersen            38.9           17.8              181.0   \n",
            "7  Adelie  Torgersen            39.2           19.6              195.0   \n",
            "8  Adelie  Torgersen            34.1           18.1              193.0   \n",
            "9  Adelie  Torgersen            42.0           20.2              190.0   \n",
            "\n",
            "   body_mass_g     sex  year  \n",
            "0       3750.0    male  2007  \n",
            "1       3800.0  female  2007  \n",
            "2       3250.0  female  2007  \n",
            "3          NaN     NaN  2007  \n",
            "4       3450.0  female  2007  \n",
            "5       3650.0    male  2007  \n",
            "6       3625.0  female  2007  \n",
            "7       4675.0    male  2007  \n",
            "8       3475.0     NaN  2007  \n",
            "9       4250.0     NaN  2007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) I can't find penguins.csv in the data folder under the assignments."
      ],
      "metadata": {
        "id": "DE0pW7JPBB1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pandas.read_csv()"
      ],
      "metadata": {
        "id": "FH6ebfD_BDhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) couldn't load data"
      ],
      "metadata": {
        "id": "zNT8NCfWB8I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f)"
      ],
      "metadata": {
        "id": "XnjPS6ZgCKFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins[penguins.isnull().any(axis=1)]\n",
        "penguins.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ7bMX3WB9LX",
        "outputId": "fc5636e6-7b5f-4cbd-d8dd-730a7e1fbf80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(19)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "g)"
      ],
      "metadata": {
        "id": "irmLiIlvDpHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins['species'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "BHP9b98lDqji",
        "outputId": "d5a6b098-1d57-4e59-9516-ac0b261f19f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "species\n",
              "Adelie       152\n",
              "Gentoo       124\n",
              "Chinstrap     68\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>species</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adelie</th>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gentoo</th>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chinstrap</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "h)"
      ],
      "metadata": {
        "id": "uYFaN0tQD4Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(penguins.dropna)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMDft4ThETWD",
        "outputId": "1846e7e2-cd26-4a99-c048-0a88788d3315"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method dropna in module pandas.core.frame:\n",
            "\n",
            "dropna(*, axis: 'Axis' = 0, how: 'AnyAll | lib.NoDefault' = <no_default>, thresh: 'int | lib.NoDefault' = <no_default>, subset: 'IndexLabel | None' = None, inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None' method of pandas.core.frame.DataFrame instance\n",
            "    Remove missing values.\n",
            "\n",
            "    See the :ref:`User Guide <missing_data>` for more on which values are\n",
            "    considered missing, and how to work with missing data.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
            "        Determine if rows or columns which contain missing values are\n",
            "        removed.\n",
            "\n",
            "        * 0, or 'index' : Drop rows which contain missing values.\n",
            "        * 1, or 'columns' : Drop columns which contain missing value.\n",
            "\n",
            "        Only a single axis is allowed.\n",
            "\n",
            "    how : {'any', 'all'}, default 'any'\n",
            "        Determine if row or column is removed from DataFrame, when we have\n",
            "        at least one NA or all NA.\n",
            "\n",
            "        * 'any' : If any NA values are present, drop that row or column.\n",
            "        * 'all' : If all values are NA, drop that row or column.\n",
            "\n",
            "    thresh : int, optional\n",
            "        Require that many non-NA values. Cannot be combined with how.\n",
            "    subset : column label or sequence of labels, optional\n",
            "        Labels along other axis to consider, e.g. if you are dropping rows\n",
            "        these would be a list of columns to include.\n",
            "    inplace : bool, default False\n",
            "        Whether to modify the DataFrame rather than creating a new one.\n",
            "    ignore_index : bool, default ``False``\n",
            "        If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.\n",
            "\n",
            "        .. versionadded:: 2.0.0\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    DataFrame or None\n",
            "        DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    DataFrame.isna: Indicate missing values.\n",
            "    DataFrame.notna : Indicate existing (non-missing) values.\n",
            "    DataFrame.fillna : Replace missing values.\n",
            "    Series.dropna : Drop missing values.\n",
            "    Index.dropna : Drop missing indices.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
            "    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
            "    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
            "    ...                             pd.NaT]})\n",
            "    >>> df\n",
            "           name        toy       born\n",
            "    0    Alfred        NaN        NaT\n",
            "    1    Batman  Batmobile 1940-04-25\n",
            "    2  Catwoman   Bullwhip        NaT\n",
            "\n",
            "    Drop the rows where at least one element is missing.\n",
            "\n",
            "    >>> df.dropna()\n",
            "         name        toy       born\n",
            "    1  Batman  Batmobile 1940-04-25\n",
            "\n",
            "    Drop the columns where at least one element is missing.\n",
            "\n",
            "    >>> df.dropna(axis='columns')\n",
            "           name\n",
            "    0    Alfred\n",
            "    1    Batman\n",
            "    2  Catwoman\n",
            "\n",
            "    Drop the rows where all elements are missing.\n",
            "\n",
            "    >>> df.dropna(how='all')\n",
            "           name        toy       born\n",
            "    0    Alfred        NaN        NaT\n",
            "    1    Batman  Batmobile 1940-04-25\n",
            "    2  Catwoman   Bullwhip        NaT\n",
            "\n",
            "    Keep only the rows with at least 2 non-NA values.\n",
            "\n",
            "    >>> df.dropna(thresh=2)\n",
            "           name        toy       born\n",
            "    1    Batman  Batmobile 1940-04-25\n",
            "    2  Catwoman   Bullwhip        NaT\n",
            "\n",
            "    Define in which columns to look for missing values.\n",
            "\n",
            "    >>> df.dropna(subset=['name', 'toy'])\n",
            "           name        toy       born\n",
            "    1    Batman  Batmobile 1940-04-25\n",
            "    2  Catwoman   Bullwhip        NaT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "penguins_cleaned = penguins.dropna()"
      ],
      "metadata": {
        "id": "fEodajfVD5ig"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "penguins_cleaned['species'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "o9aV1OuoEIOK",
        "outputId": "95e5e7aa-6d41-461e-b554-561966c93a44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "species\n",
              "Adelie       146\n",
              "Gentoo       119\n",
              "Chinstrap     68\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>species</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adelie</th>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gentoo</th>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chinstrap</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numer of Adelie and Gentoo penguins is less after the rows with missing values were dropped."
      ],
      "metadata": {
        "id": "2HvI9G8ME3fA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i)"
      ],
      "metadata": {
        "id": "TF5R0mckFFxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(penguins.describe)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElqvYxgHFHV1",
        "outputId": "f099cd3d-53ec-407c-b53a-e46b4c46cce5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method describe in module pandas.core.generic:\n",
            "\n",
            "describe(percentiles=None, include=None, exclude=None) -> 'Self' method of pandas.core.frame.DataFrame instance\n",
            "    Generate descriptive statistics.\n",
            "\n",
            "    Descriptive statistics include those that summarize the central\n",
            "    tendency, dispersion and shape of a\n",
            "    dataset's distribution, excluding ``NaN`` values.\n",
            "\n",
            "    Analyzes both numeric and object series, as well\n",
            "    as ``DataFrame`` column sets of mixed data types. The output\n",
            "    will vary depending on what is provided. Refer to the notes\n",
            "    below for more detail.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    percentiles : list-like of numbers, optional\n",
            "        The percentiles to include in the output. All should\n",
            "        fall between 0 and 1. The default is\n",
            "        ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
            "        75th percentiles.\n",
            "    include : 'all', list-like of dtypes or None (default), optional\n",
            "        A white list of data types to include in the result. Ignored\n",
            "        for ``Series``. Here are the options:\n",
            "\n",
            "        - 'all' : All columns of the input will be included in the output.\n",
            "        - A list-like of dtypes : Limits the results to the\n",
            "          provided data types.\n",
            "          To limit the result to numeric types submit\n",
            "          ``numpy.number``. To limit it instead to object columns submit\n",
            "          the ``numpy.object`` data type. Strings\n",
            "          can also be used in the style of\n",
            "          ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
            "          select pandas categorical columns, use ``'category'``\n",
            "        - None (default) : The result will include all numeric columns.\n",
            "    exclude : list-like of dtypes or None (default), optional,\n",
            "        A black list of data types to omit from the result. Ignored\n",
            "        for ``Series``. Here are the options:\n",
            "\n",
            "        - A list-like of dtypes : Excludes the provided data types\n",
            "          from the result. To exclude numeric types submit\n",
            "          ``numpy.number``. To exclude object columns submit the data\n",
            "          type ``numpy.object``. Strings can also be used in the style of\n",
            "          ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
            "          exclude pandas categorical columns, use ``'category'``\n",
            "        - None (default) : The result will exclude nothing.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    Series or DataFrame\n",
            "        Summary statistics of the Series or Dataframe provided.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    DataFrame.count: Count number of non-NA/null observations.\n",
            "    DataFrame.max: Maximum of the values in the object.\n",
            "    DataFrame.min: Minimum of the values in the object.\n",
            "    DataFrame.mean: Mean of the values.\n",
            "    DataFrame.std: Standard deviation of the observations.\n",
            "    DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
            "        columns based on their dtype.\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "    For numeric data, the result's index will include ``count``,\n",
            "    ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
            "    upper percentiles. By default the lower percentile is ``25`` and the\n",
            "    upper percentile is ``75``. The ``50`` percentile is the\n",
            "    same as the median.\n",
            "\n",
            "    For object data (e.g. strings or timestamps), the result's index\n",
            "    will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
            "    is the most common value. The ``freq`` is the most common value's\n",
            "    frequency. Timestamps also include the ``first`` and ``last`` items.\n",
            "\n",
            "    If multiple object values have the highest count, then the\n",
            "    ``count`` and ``top`` results will be arbitrarily chosen from\n",
            "    among those with the highest count.\n",
            "\n",
            "    For mixed data types provided via a ``DataFrame``, the default is to\n",
            "    return only an analysis of numeric columns. If the dataframe consists\n",
            "    only of object and categorical data without any numeric columns, the\n",
            "    default is to return an analysis of both the object and categorical\n",
            "    columns. If ``include='all'`` is provided as an option, the result\n",
            "    will include a union of attributes of each type.\n",
            "\n",
            "    The `include` and `exclude` parameters can be used to limit\n",
            "    which columns in a ``DataFrame`` are analyzed for the output.\n",
            "    The parameters are ignored when analyzing a ``Series``.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    Describing a numeric ``Series``.\n",
            "\n",
            "    >>> s = pd.Series([1, 2, 3])\n",
            "    >>> s.describe()\n",
            "    count    3.0\n",
            "    mean     2.0\n",
            "    std      1.0\n",
            "    min      1.0\n",
            "    25%      1.5\n",
            "    50%      2.0\n",
            "    75%      2.5\n",
            "    max      3.0\n",
            "    dtype: float64\n",
            "\n",
            "    Describing a categorical ``Series``.\n",
            "\n",
            "    >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
            "    >>> s.describe()\n",
            "    count     4\n",
            "    unique    3\n",
            "    top       a\n",
            "    freq      2\n",
            "    dtype: object\n",
            "\n",
            "    Describing a timestamp ``Series``.\n",
            "\n",
            "    >>> s = pd.Series([\n",
            "    ...     np.datetime64(\"2000-01-01\"),\n",
            "    ...     np.datetime64(\"2010-01-01\"),\n",
            "    ...     np.datetime64(\"2010-01-01\")\n",
            "    ... ])\n",
            "    >>> s.describe()\n",
            "    count                      3\n",
            "    mean     2006-09-01 08:00:00\n",
            "    min      2000-01-01 00:00:00\n",
            "    25%      2004-12-31 12:00:00\n",
            "    50%      2010-01-01 00:00:00\n",
            "    75%      2010-01-01 00:00:00\n",
            "    max      2010-01-01 00:00:00\n",
            "    dtype: object\n",
            "\n",
            "    Describing a ``DataFrame``. By default only numeric fields\n",
            "    are returned.\n",
            "\n",
            "    >>> df = pd.DataFrame({'categorical': pd.Categorical(['d', 'e', 'f']),\n",
            "    ...                    'numeric': [1, 2, 3],\n",
            "    ...                    'object': ['a', 'b', 'c']\n",
            "    ...                    })\n",
            "    >>> df.describe()\n",
            "           numeric\n",
            "    count      3.0\n",
            "    mean       2.0\n",
            "    std        1.0\n",
            "    min        1.0\n",
            "    25%        1.5\n",
            "    50%        2.0\n",
            "    75%        2.5\n",
            "    max        3.0\n",
            "\n",
            "    Describing all columns of a ``DataFrame`` regardless of data type.\n",
            "\n",
            "    >>> df.describe(include='all')  # doctest: +SKIP\n",
            "           categorical  numeric object\n",
            "    count            3      3.0      3\n",
            "    unique           3      NaN      3\n",
            "    top              f      NaN      a\n",
            "    freq             1      NaN      1\n",
            "    mean           NaN      2.0    NaN\n",
            "    std            NaN      1.0    NaN\n",
            "    min            NaN      1.0    NaN\n",
            "    25%            NaN      1.5    NaN\n",
            "    50%            NaN      2.0    NaN\n",
            "    75%            NaN      2.5    NaN\n",
            "    max            NaN      3.0    NaN\n",
            "\n",
            "    Describing a column from a ``DataFrame`` by accessing it as\n",
            "    an attribute.\n",
            "\n",
            "    >>> df.numeric.describe()\n",
            "    count    3.0\n",
            "    mean     2.0\n",
            "    std      1.0\n",
            "    min      1.0\n",
            "    25%      1.5\n",
            "    50%      2.0\n",
            "    75%      2.5\n",
            "    max      3.0\n",
            "    Name: numeric, dtype: float64\n",
            "\n",
            "    Including only numeric columns in a ``DataFrame`` description.\n",
            "\n",
            "    >>> df.describe(include=[np.number])\n",
            "           numeric\n",
            "    count      3.0\n",
            "    mean       2.0\n",
            "    std        1.0\n",
            "    min        1.0\n",
            "    25%        1.5\n",
            "    50%        2.0\n",
            "    75%        2.5\n",
            "    max        3.0\n",
            "\n",
            "    Including only string columns in a ``DataFrame`` description.\n",
            "\n",
            "    >>> df.describe(include=[object])  # doctest: +SKIP\n",
            "           object\n",
            "    count       3\n",
            "    unique      3\n",
            "    top         a\n",
            "    freq        1\n",
            "\n",
            "    Including only categorical columns from a ``DataFrame`` description.\n",
            "\n",
            "    >>> df.describe(include=['category'])\n",
            "           categorical\n",
            "    count            3\n",
            "    unique           3\n",
            "    top              d\n",
            "    freq             1\n",
            "\n",
            "    Excluding numeric columns from a ``DataFrame`` description.\n",
            "\n",
            "    >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
            "           categorical object\n",
            "    count            3      3\n",
            "    unique           3      3\n",
            "    top              f      a\n",
            "    freq             1      1\n",
            "\n",
            "    Excluding object columns from a ``DataFrame`` description.\n",
            "\n",
            "    >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
            "           categorical  numeric\n",
            "    count            3      3.0\n",
            "    unique           3      NaN\n",
            "    top              f      NaN\n",
            "    freq             1      NaN\n",
            "    mean           NaN      2.0\n",
            "    std            NaN      1.0\n",
            "    min            NaN      1.0\n",
            "    25%            NaN      1.5\n",
            "    50%            NaN      2.0\n",
            "    75%            NaN      2.5\n",
            "    max            NaN      3.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(penguins.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rj1h4L9FWJq",
        "outputId": "2c6a7b92-e305-486e-866c-6ccf73938a1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
            "count      342.000000     342.000000         342.000000   342.000000   \n",
            "mean        43.921930      17.151170         200.915205  4201.754386   \n",
            "std          5.459584       1.974793          14.061714   801.954536   \n",
            "min         32.100000      13.100000         172.000000  2700.000000   \n",
            "25%         39.225000      15.600000         190.000000  3550.000000   \n",
            "50%         44.450000      17.300000         197.000000  4050.000000   \n",
            "75%         48.500000      18.700000         213.000000  4750.000000   \n",
            "max         59.600000      21.500000         231.000000  6300.000000   \n",
            "\n",
            "              year  \n",
            "count   344.000000  \n",
            "mean   2008.029070  \n",
            "std       0.818356  \n",
            "min    2007.000000  \n",
            "25%    2007.000000  \n",
            "50%    2008.000000  \n",
            "75%    2009.000000  \n",
            "max    2009.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns that are not numerical variables are missing. Catagorical veriables do not have quantiles, averages or standard deviations."
      ],
      "metadata": {
        "id": "TKRjhF65Fnvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "j)"
      ],
      "metadata": {
        "id": "Vw2qSoHvGMof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins['body_mass_g'] = penguins['body_mass_kg'] / 1000"
      ],
      "metadata": {
        "id": "3ag4gMrwGJPt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(penguins.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aUZk8M5GKZ2",
        "outputId": "6614e3dd-5a5a-4ef1-89df-baf2739c0dd1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
            "count      342.000000     342.000000         342.000000   342.000000   \n",
            "mean        43.921930      17.151170         200.915205     0.004202   \n",
            "std          5.459584       1.974793          14.061714     0.000802   \n",
            "min         32.100000      13.100000         172.000000     0.002700   \n",
            "25%         39.225000      15.600000         190.000000     0.003550   \n",
            "50%         44.450000      17.300000         197.000000     0.004050   \n",
            "75%         48.500000      18.700000         213.000000     0.004750   \n",
            "max         59.600000      21.500000         231.000000     0.006300   \n",
            "\n",
            "              year  body_mass_kg  \n",
            "count   344.000000    342.000000  \n",
            "mean   2008.029070      4.201754  \n",
            "std       0.818356      0.801955  \n",
            "min    2007.000000      2.700000  \n",
            "25%    2007.000000      3.550000  \n",
            "50%    2008.000000      4.050000  \n",
            "75%    2009.000000      4.750000  \n",
            "max    2009.000000      6.300000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(penguins.astype)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrgQbeH6Hm6X",
        "outputId": "df4dfb7d-ceb4-49ad-bf99-d5d4b9bd7e30"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method astype in module pandas.core.generic:\n",
            "\n",
            "astype(dtype, copy: 'bool_t | None' = None, errors: 'IgnoreRaise' = 'raise') -> 'Self' method of pandas.core.frame.DataFrame instance\n",
            "    Cast a pandas object to a specified dtype ``dtype``.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    dtype : str, data type, Series or Mapping of column name -> data type\n",
            "        Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\n",
            "        cast entire pandas object to the same type. Alternatively, use a\n",
            "        mapping, e.g. {col: dtype, ...}, where col is a column label and dtype is\n",
            "        a numpy.dtype or Python type to cast one or more of the DataFrame's\n",
            "        columns to column-specific types.\n",
            "    copy : bool, default True\n",
            "        Return a copy when ``copy=True`` (be very careful setting\n",
            "        ``copy=False`` as changes to values then may propagate to other\n",
            "        pandas objects).\n",
            "\n",
            "        .. note::\n",
            "            The `copy` keyword will change behavior in pandas 3.0.\n",
            "            `Copy-on-Write\n",
            "            <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
            "            will be enabled by default, which means that all methods with a\n",
            "            `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
            "            ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
            "            future version of pandas.\n",
            "\n",
            "            You can already get the future behavior and improvements through\n",
            "            enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
            "    errors : {'raise', 'ignore'}, default 'raise'\n",
            "        Control raising of exceptions on invalid data for provided dtype.\n",
            "\n",
            "        - ``raise`` : allow exceptions to be raised\n",
            "        - ``ignore`` : suppress exceptions. On error return original object.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    same type as caller\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    to_datetime : Convert argument to datetime.\n",
            "    to_timedelta : Convert argument to timedelta.\n",
            "    to_numeric : Convert argument to a numeric type.\n",
            "    numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "    .. versionchanged:: 2.0.0\n",
            "\n",
            "        Using ``astype`` to convert from timezone-naive dtype to\n",
            "        timezone-aware dtype will raise an exception.\n",
            "        Use :meth:`Series.dt.tz_localize` instead.\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    Create a DataFrame:\n",
            "\n",
            "    >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
            "    >>> df = pd.DataFrame(data=d)\n",
            "    >>> df.dtypes\n",
            "    col1    int64\n",
            "    col2    int64\n",
            "    dtype: object\n",
            "\n",
            "    Cast all columns to int32:\n",
            "\n",
            "    >>> df.astype('int32').dtypes\n",
            "    col1    int32\n",
            "    col2    int32\n",
            "    dtype: object\n",
            "\n",
            "    Cast col1 to int32 using a dictionary:\n",
            "\n",
            "    >>> df.astype({'col1': 'int32'}).dtypes\n",
            "    col1    int32\n",
            "    col2    int64\n",
            "    dtype: object\n",
            "\n",
            "    Create a series:\n",
            "\n",
            "    >>> ser = pd.Series([1, 2], dtype='int32')\n",
            "    >>> ser\n",
            "    0    1\n",
            "    1    2\n",
            "    dtype: int32\n",
            "    >>> ser.astype('int64')\n",
            "    0    1\n",
            "    1    2\n",
            "    dtype: int64\n",
            "\n",
            "    Convert to categorical type:\n",
            "\n",
            "    >>> ser.astype('category')\n",
            "    0    1\n",
            "    1    2\n",
            "    dtype: category\n",
            "    Categories (2, int32): [1, 2]\n",
            "\n",
            "    Convert to ordered categorical type with custom ordering:\n",
            "\n",
            "    >>> from pandas.api.types import CategoricalDtype\n",
            "    >>> cat_dtype = CategoricalDtype(\n",
            "    ...     categories=[2, 1], ordered=True)\n",
            "    >>> ser.astype(cat_dtype)\n",
            "    0    1\n",
            "    1    2\n",
            "    dtype: category\n",
            "    Categories (2, int64): [2 < 1]\n",
            "\n",
            "    Create a series of dates:\n",
            "\n",
            "    >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
            "    >>> ser_date\n",
            "    0   2020-01-01\n",
            "    1   2020-01-02\n",
            "    2   2020-01-03\n",
            "    dtype: datetime64[ns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "penguins['sex_num'] = penguins['sex'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "Ha2AP8MXHM1O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(penguins.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-US_mlUH2Rp",
        "outputId": "86e173fe-3fac-46ec-96b2-790671abb76d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
            "count      342.000000     342.000000         342.000000   342.000000   \n",
            "mean        43.921930      17.151170         200.915205     0.004202   \n",
            "std          5.459584       1.974793          14.061714     0.000802   \n",
            "min         32.100000      13.100000         172.000000     0.002700   \n",
            "25%         39.225000      15.600000         190.000000     0.003550   \n",
            "50%         44.450000      17.300000         197.000000     0.004050   \n",
            "75%         48.500000      18.700000         213.000000     0.004750   \n",
            "max         59.600000      21.500000         231.000000     0.006300   \n",
            "\n",
            "              year  body_mass_kg     sex_num  \n",
            "count   344.000000    342.000000  344.000000  \n",
            "mean   2008.029070      4.201754    0.456395  \n",
            "std       0.818356      0.801955    0.559430  \n",
            "min    2007.000000      2.700000   -1.000000  \n",
            "25%    2007.000000      3.550000    0.000000  \n",
            "50%    2008.000000      4.050000    0.000000  \n",
            "75%    2009.000000      4.750000    1.000000  \n",
            "max    2009.000000      6.300000    1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'sex' column now shows up in the .describe function. Though there are negative values in that column of the data set."
      ],
      "metadata": {
        "id": "MzjMNbd_Ilek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uENxx9_VTZAD"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzvGVzgTZAE"
      },
      "source": [
        "## 2\n",
        "**[40 points]** Visualization\n",
        "\n",
        "In data science, we often need to have a sense of the idiosyncrasies of the data, how they relate to the questions we are trying to answer, and to use that information to help us to determine what approach we may need to apply to achieve our goal. This exercise provides practice in exploring a dataset and answering question that might arise from applications related to the data.\n",
        "\n",
        "\n",
        "**Data**. Use the `penguins_cleaned` dataframe for the following questions\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, your goal is to follow these instructions and answer the following questions:\n",
        "\n",
        "_The following questions are work 5 points each._\n",
        "\n",
        "**(a)** Plot a bar plot of the number of samples from each species. There are a LOT of ways to do this!  Try at least 2 (for example... you can use the pandas `.plot()` method, you can use `matplotlib.pyplot`, and you can use a cool library called `seaborn`).  \n",
        "\n",
        "**(b)** On the sample plot, create boxplots for the variables: `'bill_length_mm'` `'bill_depth_mm'` `'flipper_length_mm'`.\n",
        "\n",
        "**(c)** On the sample plot, create violin plots for the variables: `'bill_length_mm'` `'bill_depth_mm'` `'flipper_length_mm'`.  How is this different from the boxplots?  What do we gain from this?\n",
        "\n",
        "**(d)** Plot a scatterplot with the `'bill_length_mm'` on the x-axis and `'bill_depth_mm'` on the y-axis, and the points colored by species.   \n",
        "\n",
        "**(bonus +1 point)**  Add regression lines by species to this scatterplot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASw0yPhTZAE"
      },
      "source": [
        "**ANSWER**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7LwEpCTZAE"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "## 3\n",
        "**[10 points]** Your goal is to explore the [datasets available](https://github.com/lucywowen/csci191_ProgSci/tree/main/data/prog_sci_data) and identify questions or problems you're interested in working with.  \n",
        "\n",
        "1. Find 2 datasets that interest you from [here](https://github.com/lucywowen/csci191_ProgSci/tree/main/data/prog_sci_data).\n",
        "\n",
        "2. For each of the 2 datasets, describe the dataset, the source of the data, and the reason the dataset was of interest. What question are you hoping to answer through exploring the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l56U-8r9TZAE"
      },
      "source": [
        "**ANSWER**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "643px",
        "left": "1548px",
        "right": "20px",
        "top": "121px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}